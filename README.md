# Reference-Links
Curated list of articles for ML/AI/NLP


## Deep Learning:

* The Perceptron Learning Algorithm and its Convergence: https://www.cse.iitb.ac.in/~shivaram/teaching/old/cs344+386-s2017/resources/classnote-1.pdf
* Deep Dive into Math Behind Deep Networks: https://towardsdatascience.com/https-medium-com-piotr-skalski92-deep-dive-into-deep-networks-math-17660bc376ba
* Recent Advances for a Better Understanding of Deep Learning âˆ’ Part I: https://towardsdatascience.com/recent-advances-for-a-better-understanding-of-deep-learning-part-i-5ce34d1cc914
* using neural nets to recognize handwritten digits: http://neuralnetworksanddeeplearning.com/chap1.html
* Tinker with Neural Networks in browser: https://playground.tensorflow.org
* Dimensions and manifolds: https://datascience.stackexchange.com/questions/5694/dimensionality-and-manifold
* Play with Generative Adverserial Networks: https://poloclub.github.io/ganlab/
* Overfitting and how to prevent it: https://hackernoon.com/memorizing-is-not-learning-6-tricks-to-prevent-overfitting-in-machine-learning-820b091dc42
* 37 reasons for neural n/w not working properly: https://blog.slavv.com/37-reasons-why-your-neural-network-is-not-working-4020854bd607
* list of cost functions to be used with Gradient Descent: https://stats.stackexchange.com/questions/154879/a-list-of-cost-functions-used-in-neural-networks-alongside-applications

### CNN and Image Processing:

* Why do we need to normalize the images before we put them into CNN? : https://stats.stackexchange.com/questions/185853/why-do-we-need-to-normalize-the-images-before-we-put-them-into-cnn
* Neural Network data type conversion - float from int? : https://datascience.stackexchange.com/questions/13636/neural-network-data-type-conversion-float-from-int
* Image Pre-processing (Keras): https://keras.io/preprocessing/image/
* Trick to prevent Overfitting: https://hackernoon.com/memorizing-is-not-learning-6-tricks-to-prevent-overfitting-in-machine-learning-820b091dc42
* keras callbacks: https://keras.io/callbacks/
* How to Check-Point Deep Learning Models in Keras: https://machinelearningmastery.com/check-point-deep-learning-models-keras/
* In Depth understanding of Convolutions: http://timdettmers.com/2015/03/26/convolution-deep-learning/
* friendly introduction to Cross Entropy: https://rdipietro.github.io/friendly-intro-to-cross-entropy-loss/
* Understanding Cross Entropy Loss - Visual Information Theory: http://timdettmers.com/2015/03/26/convolution-deep-learning/
* Papers on imp CNN architectures: https://adeshpande3.github.io/adeshpande3.github.io/The-9-Deep-Learning-Papers-You-Need-To-Know-About.html
* CNN using numpy: https://becominghuman.ai/only-numpy-implementing-convolutional-neural-network-using-numpy-deriving-forward-feed-and-back-458a5250d6e4
* Image Transformations Using OpenCV: https://docs.opencv.org/trunk/d9/d61/tutorial_py_morphological_ops.html
* List of Open Source **Medical Image Analysis** Softwares:http://www0.cs.ucl.ac.uk/opensource_mia_ws_2012/links.html
* Natural Images: https://stats.stackexchange.com/questions/25737/definition-of-natural-images-in-the-context-of-machine-learning
* ResNet - understanding the bottleneck unit: https://stats.stackexchange.com/questions/347280/regarding-the-understanding-of-bottleneck-unit-of-resnet

* https://github.com/anujshah1003/VQA-Demo-GUI
* https://iamaaditya.github.io/2016/04/visual_question_answering_demo_notebook

* CNN+LSTM: https://machinelearningmastery.com/cnn-long-short-term-memory-networks/

**keras embedding layer**
* Using Embedding Layer in Keras: https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html
* how does keras embedding layer work: https://stats.stackexchange.com/questions/270546/how-does-keras-embedding-layer-work

**Doc2Vec**
* Doc2Vec : https://radimrehurek.com/gensim/models/doc2vec.html
* https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/doc2vec-lee.ipynb
* Doc2Vec : https://medium.com/@mishra.thedeepak/doc2vec-simple-implementation-example-df2afbbfbad5
* How to use Doc2Vec as input to Keras model: https://stackoverflow.com/questions/50564928/how-to-use-sentence-vectors-from-doc2vec-in-keras-sequntial-model-for-sentence-s

**NLG**
* NLG using markovify: https://github.com/jsvine/markovify
* training bot to comment on current affairs: https://www.kaggle.com/aashita/training-a-bot-to-comment-on-current-affairs

* plotting boxplots in plotly in python: https://plot.ly/python/box-plots/
* extract high correlation values: https://stackoverflow.com/questions/17778394/list-highest-correlation-pairs-from-a-large-correlation-matrix-in-pandas
* converting group by object to data frame (also how to avoid converting columns to indices when doing group by):https://stackoverflow.com/questions/10373660/converting-a-pandas-groupby-object-to-dataframe

* **matplotlib** basic tutorial: https://www.datacamp.com/community/tutorials/matplotlib-tutorial-python

* parametric and non-parametric ml methods: https://machinelearningmastery.com/parametric-and-nonparametric-machine-learning-algorithms/
* Stability Selection vs RFE (Recursive Feature Elimination): http://blog.datadive.net/selecting-good-features-part-iv-stability-selection-rfe-and-everything-side-by-side/

* Progress Bars in jupyter notebook with tqdm : https://towardsdatascience.com/progress-bars-in-python-4b44e8a4c482

* **Scikit learn**: http://scikit-learn.org/stable/index.html
* text tutorial: https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html
* text classification ref: https://scikit-learn.org/0.19/auto_examples/text/document_classification_20newsgroups.html#sphx-glr-auto-examples-text-document-classification-20newsgroups-py


## feature scaling
* Standardisation vs Normalization:  https://stackoverflow.com/questions/32108179/linear-regression-normalization-vs-standardization
* Importance of Feature Scaling: http://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html
* feature Scaling with scikit-learn (good): http://benalexkeen.com/feature-scaling-with-scikit-learn/
* about feature scaling (bit mathematical): http://sebastianraschka.com/Articles/2014_about_feature_scaling.html


* How is Bayesian classifer different from MLE classifier?: https://stats.stackexchange.com/questions/74082/what-is-the-difference-in-bayesian-estimate-and-maximum-likelihood-estimate
* Cross Validation - need for test set: https://stats.stackexchange.com/questions/223408/how-does-k-fold-cross-validation-fit-in-the-context-of-training-validation-testi AND
https://stackoverflow.com/questions/43663365/cross-validation-use-testing-set-or-validation-set-to-predict
* K Modes Clustering: https://shapeofdata.wordpress.com/2014/03/04/k-modes/
* Hirarchial Clustering: http://www.saedsayad.com/clustering_hierarchical.htm
* Linkage methods of hierarchical agglomerative cluster analysis (HAC): https://stats.stackexchange.com/questions/195446/choosing-the-right-linkage-method-for-hierarchical-clustering
* why LASSO shrinkag works: https://stats.stackexchange.com/questions/179864/why-does-shrinkage-work
* p value: https://www.statsdirect.com/help/basics/p_values.htm
* multicollinearity in regression analysis: http://statisticsbyjim.com/regression/multicollinearity-in-regression-analysis/
* Effect of multicollinearity on Ordinary Least Squares solution for regression: https://en.wikipedia.org/wiki/Multicollinearity
* Why is gradient descent or optimization methods required at all if cost function minima can be found directly say by using linear algebra or differentiation ? : https://stats.stackexchange.com/questions/212619/why-is-gradient-descent-required
https://stats.stackexchange.com/questions/278755/why-use-gradient-descent-for-linear-regression-when-a-closed-form-math-solution
* normality tests in python: https://machinelearningmastery.com/a-gentle-introduction-to-normality-tests-in-python/
* parametric significance tests in python: https://machinelearningmastery.com/parametric-statistical-significance-tests-in-python/
* non-parametric significance tests in python: https://machinelearningmastery.com/nonparametric-statistical-significance-tests-in-python/
* Introduction to Matrix Decomposition: https://machinelearningmastery.com/introduction-to-matrix-decompositions-for-machine-learning/
* How to Compare ML models: https://machinelearningmastery.com/compare-machine-learning-algorithms-python-scikit-learn/
* Beginners guide to Jupyter Notebooks: https://www.analyticsvidhya.com/blog/2018/05/starters-guide-jupyter-notebook/?utm_source=feedburner&utm_medium=email&utm_campaign=Feed%3A+AnalyticsVidhya+%28Analytics+Vidhya%29
* matplotlib plotting in 2D and 3D: http://nbviewer.jupyter.org/github/jrjohansson/scientific-python-lectures/blob/master/Lecture-4-Matplotlib.ipynb
* Computational Quantum Mechanics with Python: http://jrjohansson.github.io/
* difference between generative and discriminative algorithm: https://stackoverflow.com/questions/879432/what-is-the-difference-between-a-generative-and-discriminative-algorithm
* What is the difference between Liklihood and probability: https://stackoverflow.com/questions/879432/what-is-the-difference-between-a-generative-and-discriminative-algorithm

#### frequentist AB testing:
* http://ethen8181.github.io/machine-learning/ab_tests/frequentist_ab_test.html

##### ANOVA tests:
* https://machinelearningmastery.com/parametric-statistical-significance-tests-in-python/
* https://pythonfordatascience.org/anova-python/
* https://riffyn.com/riffyn-blog/2017/10/29/family-wise-error-rate

#### Feature reduction:

* feature reduction using varrank: https://cran.r-project.org/web/packages/varrank/vignettes/varrank.html

#### dummy vars
* dummy vars transfromation applied on prediction data: https://stackoverflow.com/questions/43578799/how-to-save-mapping-of-data-frame-to-model-matrix-and-apply-to-new-observations

**Pipelines in sklearn**

* Pipelines and composite estimators: https://scikit-learn.org/stable/modules/compose.html#
* Deep dive into sklearn pipelines: https://www.kaggle.com/baghern/a-deep-dive-into-sklearn-pipelines
* Feature Union: https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.FeatureUnion.html#sklearn.pipeline.FeatureUnion
* Column Transformer with Heterogeneous Data Sources: https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer.html#sphx-glr-auto-examples-compose-plot-column-transformer-py

## Boosting:
* A gentle introduction to boosting algos: https://machinelearningmastery.com/gentle-introduction-gradient-boosting-algorithm-machine-learning/
* CatBoost Algorithm resources: https://tech.yandex.com/catboost/
* Light GBM: http://lightgbm.readthedocs.io/en/latest/index.html
* Light GBM github: https://github.com/Microsoft/LightGBM
* XGBoost Conceptual Understanding of Algo: http://xgboost.readthedocs.io/en/latest/model.html
* XGBoost Site: http://xgboost.readthedocs.io/en/latest/


* Difference b/w size and count with groupby in pandas: https://stackoverflow.com/questions/33346591/what-is-the-difference-between-size-and-count-in-pandas
* ML crash course by google: https://developers.google.com/machine-learning/crash-course/prereqs-and-prework
* pandas regex to create columns: https://chrisalbon.com/python/data_wrangling/pandas_regex_to_create_columns/
* regex in python and pandas: https://www.dataquest.io/blog/regular-expressions-data-scientists/

* Book on Feature Engineering (Max Kuhn): http://www.feat.engineering/
* Understanding Cost Functions (video series): https://www.youtube.com/watch?v=euhATa4wgzo&index=1&list=PLNlkREaquqc6WUPMRicPbEvLyZe-7b-GT
* Build better predictive models using segmentation: https://www.analyticsvidhya.com/blog/2016/02/guide-build-predictive-models-segmentation/
* using AWS for Deep Learning: https://machinelearningmastery.com/develop-evaluate-large-deep-learning-models-keras-amazon-web-services/

#### Metrics for ML model evaluation
* metrics for model evaluation: http://scikit-learn.org/stable/modules/model_evaluation.html
* f1 score macro vs micro: https://datascience.stackexchange.com/questions/40900/whats-the-difference-between-sklearn-f1-score-micro-and-weighted-for-a-mult
* when to use f1 macro vs f1 micro:https://datascience.stackexchange.com/questions/36862/macro-or-micro-average-for-imbalanced-class-problems
* Top 15: https://www.machinelearningplus.com/machine-learning/evaluation-metrics-classification-models-r/
* ROC : https://stats.stackexchange.com/questions/105501/understanding-roc-curve
* ROC detailed analysis: http://mlwiki.org/index.php/ROC_Analysis

**PCA**
* variance in PCA explained: https://ro-che.info/articles/2017-12-11-pca-explained-variance
* PCA on large matrices: https://amedee.me/post/pca-large-matrices/
* radomizedSVD: http://alimanfoo.github.io/2015/09/28/fast-pca.html

**t-SNE**
* Laurens van der Maaten's (creator of t-SNE) website: https://lvdmaaten.github.io/tsne/
* Visualising data using t-SNE: Journal of Machine Learning Research: http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf
* How to use t-SNE effectively: https://distill.pub/2016/misread-tsne/

**ICA**
* Stanford notes on ICA: http://cs229.stanford.edu/notes/cs229-notes11.pdf

**Mahalnobis distance***
* https://www.machinelearningplus.com/statistics/mahalanobis-distance/

### clustering
* assessing clustering tendancy:https://www.datanovia.com/en/lessons/assessing-clustering-tendency/
* Hopkins test for cluster tendency: https://matevzkunaver.wordpress.com/2017/06/20/hopkins-test-for-cluster-tendency/
* Clustering validation tests: http://www.sthda.com/english/wiki/print.php?id=241
* silhoutte method for cluster quality: https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html

### Latent Drichlet Analysis:
* Topic modeling in gesim:  https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/
* Topic modeling in sklearn (with NMF): https://www.machinelearningplus.com/nlp/topic-modeling-python-sklearn-examples/
* sklearn: https://scikit-learn.org/stable/auto_examples/applications/plot_topics_extraction_with_nmf_lda.html

### text summarization:
* https://becominghuman.ai/text-summarization-in-5-steps-using-nltk-65b21e352b65

### spacy
* text classification using spacy: https://www.dataquest.io/blog/tutorial-text-classification-in-python-using-spacy/
* ml for text classification using spacy: https://towardsdatascience.com/machine-learning-for-text-classification-using-spacy-in-python-b276b4051a49
* tricks for using spacy at scale: https://towardsdatascience.com/a-couple-tricks-for-using-spacy-at-scale-54affd8326cf
*	Modified skip gram based on spacy dependency parser: https://medium.com/reputation-com-datascience-blog/keywords-extraction-with-ngram-and-modified-skip-gram-based-on-spacy-14e5625fce23

### gensim
* introduction to gensim: https://www.machinelearningplus.com/nlp/gensim-tutorial/


## Docker
* https://www.analyticsvidhya.com/blog/2017/11/reproducible-data-science-docker-for-data-science/
* Docker for ML: https://pratos.github.io/2017-04-24/docker-for-data-science-part-1/
* conceptual - introduction to VM's and Docker: https://medium.freecodecamp.org/a-beginner-friendly-introduction-to-containers-vms-and-docker-79a9e3e119b

#### Handling imbalanced data set:
* how to handle imbalanced data with code: https://elitedatascience.com/imbalanced-classes
* good read: https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/
* concept read: https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/
* imbalanced-learn library: https://github.com/scikit-learn-contrib/imbalanced-learn
* anomaly detection in python: https://www.datascience.com/blog/python-anomaly-detection
* scikit learn novelty and outlier detection: https://www.datascience.com/blog/python-anomaly-detection
* Imbalanced data handling tutorial in Python: https://blog.dominodatalab.com/imbalanced-datasets/

### Multi-label Classification
* https://towardsdatascience.com/journey-to-the-center-of-multi-label-classification-384c40229bff

* sentiment analysis using VADER: https://medium.com/analytics-vidhya/simplifying-social-media-sentiment-analysis-using-vader-in-python-f9e6ec6fc52f

### Anomaly Detection
* Note on anomaly detection: https://towardsdatascience.com/a-note-about-finding-anomalies-f9cedee38f0b
* Four Techniques for Anomaly detection: https://dzone.com/articles/four-techniques-for-outlier-detection-knime
* Novelty and Outlier Detection: https://scikit-learn.org/stable/modules/outlier_detection.html#novelty-detection
* One Class SVM Anomaly detection: https://www.kaggle.com/amarnayak/once-class-svm-to-detect-anomaly
* PyOD for anomaly detection: https://github.com/yzhao062/Pyod#quick-start-for-outlier-detection
* text anomaly detection: https://arxiv.org/pdf/1701.01325.pdf

* Text Anomaly Detection using Doc2Vec and cosine sim: https://medium.com/datadriveninvestor/unsupervised-outlier-detection-in-text-corpus-using-deep-learning-41d4284a04c8
* https://github.com/avisheknag17/public_ml_models/blob/master/outlier_detection_in_movie_plots_ann/notebook/movie_plots_outlier_detector.ipynb

## NLP:
* NLTK Book: http://www.nltk.org/book/ 
* SpaCy: Industrial grad NLP: https://spacy.io/
* Genism: https://radimrehurek.com/gensim/index.html
* NLTK tutorial: https://pythonprogramming.net/tokenizing-words-sentences-nltk-tutorial/

* jaccard distance using NLP: https://python.gotrained.com/nltk-edit-distance-jaccard-distance/#Jaccard_Distance

* Lyric Analysis with NLP and ML in R part 1: https://www.datacamp.com/community/tutorials/R-nlp-machine-learning
* Lyric Analysis with NLP and ML in R part 2A:https://www.datacamp.com/community/tutorials/R-nlp-machine-learning
* Lyric Analysis with NLP and ML in R part 2B:https://www.datacamp.com/community/tutorials/sentiment-analysis-R

* Text Encoding Unicode: https://docs.python.org/3/howto/unicode.html

* Roudup of Python NLP libraries: https://nlpforhackers.io/libraries/

* Spacy Tutorial (AV): https://www.analyticsvidhya.com/blog/2017/04/natural-language-processing-made-easy-using-spacy-%E2%80%8Bin-python/
* SpaCy Tutorial: https://nlpforhackers.io/complete-guide-to-spacy/

* Generate text using word level neural language model: https://machinelearningmastery.com/how-to-develop-a-word-level-neural-language-model-in-keras/
* Generate text using LSTM: https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/

* SIF embeddings implementation: https://www.kaggle.com/procode/sif-embeddings-got-69-accuracy

**Ontology based text classification**: https://sci2lab.github.io/mehdi/icsc2014.pdf

**fast text analysis using Vowpal Wabbit :** https://www.kaggle.com/kashnitsky/vowpal-wabbit-tutorial-blazingly-fast-learning

#### transfer learning in NLP:

* BERT: https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html

* BERT Research Paper: https://arxiv.org/abs/1810.04805 
* blog: http://jalammar.github.io/
* Blog for understanding ELMO and BERT: http://jalammar.github.io/illustrated-bert/
* ULMFIT tutorial: https://www.analyticsvidhya.com/blog/2018/11/tutorial-text-classification-ulmfit-fastai-library/
* DSSM: https://www.microsoft.com/en-us/research/project/dssm/
 
### XGBoost Installation:

* check you python version - by opening CMD and typing python -> ENTER
* Go to this link and search on XGBoost: https://www.lfd.uci.edu/~gohlke/pythonlibs/
* download the installable based on python version + Windows 32 or 64 bit, for example download xgboost-0.71-cp36-cp36m-win_amd64.whl for python version 3.6 and 64 bit machine.
* open cmd in downloaded location and run the following command: pip install xgboost-0.71-cp36-cp36m-win_amd64.whl

### Spark

* Why should one use spark for ML: https://www.infoworld.com/article/3031690/analytics/why-you-should-use-spark-for-machine-learning.html

* Multi-Class Text Classification with PySpark: https://towardsdatascience.com/multi-class-text-classification-with-pyspark-7d78d022ed35

### Python
* Python OOP tutorial: https://www.youtube.com/watch?v=ZDa-Z5JzLYM
* vectorized string operations in Python(using pandas): https://jakevdp.github.io/PythonDataScienceHandbook/03.10-working-with-strings.html

* Use YouTube as a Free Screencast Recorder: https://www.youtube.com/watch?v=0i9C8GpRedc

* list comprehensions: https://www.machinelearningplus.com/python/list-comprehensions-in-python/
* Numpy 1 - basic: https://www.machinelearningplus.com/python/numpy-tutorial-part1-array-python-examples/
* Numpy 2 - advanced: https://www.machinelearningplus.com/python/numpy-tutorial-python-part2/
* Numpy 101 practice: https://www.machinelearningplus.com/python/101-numpy-exercises-python/
* Pandas 101 practice: https://www.machinelearningplus.com/python/101-pandas-exercises-python/

* Parallel processing in Python: https://www.machinelearningplus.com/python/parallel-processing-python/

##### writing better code for DS:
* https://towardsdatascience.com/how-a-simple-mix-of-object-oriented-programming-can-sharpen-your-deep-learning-prototype-19893bd969bd
* https://towardsdatascience.com/notes-on-software-construction-from-code-complete-8d2a8a959c69

#### Generators
* Jeff Knup's blog: 'Yield' and Generator Functions: https://jeffknupp.com/blog/2013/04/07/improve-your-python-yield-and-generators-explained/
* Corey Schafer (YouTube video): Generator functions: https://www.youtube.com/watch?v=bD05uGo_sVI
* Data streaming in Python: generators, iterators, iterables: https://rare-technologies.com/data-streaming-in-python-generators-iterators-iterables/

### Reinforcement Learning
* Dynamic Programming: https://web.stanford.edu/class/cs97si/04-dynamic-programming.pdf
* When are Monte Carlo methods preferred over Temporal Difference methods: https://stats.stackexchange.com/questions/336974/when-are-monte-carlo-methods-preferred-over-temporal-difference-ones
* https://simoninithomas.github.io/Deep_reinforcement_learning_Course/#
* Off-Policy Monte Carlo Control: https://cs.wmich.edu/~trenary/files/cs5300/RLBook/node56.html
* https://www.learndatasci.com/tutorials/reinforcement-q-learning-scratch-python-openai-gym/

### PGM
* Using Deep Neural Network Approximate Bayesian Network: https://arxiv.org/pdf/1801.00282.pdf
* A Comprehensive guide to Bayesian Convolutional Neural Network with Variational Inference https://arxiv.org/pdf/1901.02731.pdf
* Bayesian Methods for Hackers: https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers
* Causal Inference survey of current areas of research: https://stats.stackexchange.com/questions/328602/what-are-some-current-research-areas-of-interest-in-machine-learning-and-causal

### Open Datasets
* https://skymind.ai/wiki/open-datasets
* Chest X-ray data: https://www.kaggle.com/nih-chest-xrays

### Image Captioning
* https://towardsdatascience.com/image-captioning-with-keras-teaching-computers-to-describe-pictures-c88a46a311b8
* https://www.analyticsvidhya.com/blog/2018/04/solving-an-image-captioning-task-using-deep-learning/
* https://machinelearningmastery.com/develop-a-deep-learning-caption-generation-model-in-python/
* A Comprehensive Survey of Deep Learning for Image Captioning: https://arxiv.org/pdf/1810.04020.pdf

### Image Segmentation:
* Image Segmentation Keras : Implementation of Segnet, FCN, UNet, PSPNet and other models in Keras: https://github.com/divamgupta/image-segmentation-keras

### Customer Analytics
https://towardsdatascience.com/predictive-customer-analytics-4064d881b649 (part 1)

### Time Series
* time series analysis in python: https://www.machinelearningplus.com/time-series/time-series-analysis-python/

### Architecture
* https://towardsdatascience.com/putting-ml-in-production-i-using-apache-kafka-in-python-ce06b3a395c8
* https://towardsdatascience.com/putting-ml-in-production-ii-logging-and-monitoring-algorithms-91f174044e4e
* https://towardsdatascience.com/getting-started-with-mlflow-52eff8c09c61

## References (business):
* What is an ad impression: https://www.mediapost.com/publications/article/219695/the-definition-of-an-ad-impression.html
* ML in fraud detection: https://www.marutitech.com/machine-learning-fraud-detection/
* Customer Segmentation: http://analyticstraining.com/2011/cluster-analysis-for-business/
* Telecom churn customer model: https://parcusgroup.com/Telecom-Customer-Churn-Prediction-Models
* customer churn in mobile markets: https://arxiv.org/ftp/arxiv/papers/1607/1607.07792.pdf

