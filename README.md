# Reference-Links
Curated list of articles for ML/AI/NLP


## Deep Learning:

* The Perceptron Learning Algorithm and its Convergence: https://www.cse.iitb.ac.in/~shivaram/teaching/old/cs344+386-s2017/resources/classnote-1.pdf
* Deep Dive into Math Behind Deep Networks: https://towardsdatascience.com/https-medium-com-piotr-skalski92-deep-dive-into-deep-networks-math-17660bc376ba
* Recent Advances for a Better Understanding of Deep Learning âˆ’ Part I: https://towardsdatascience.com/recent-advances-for-a-better-understanding-of-deep-learning-part-i-5ce34d1cc914
* using neural nets to recognize handwritten digits: http://neuralnetworksanddeeplearning.com/chap1.html
* Tinker with Neural Networks in browser: https://playground.tensorflow.org
* Dimensions and manifolds: https://datascience.stackexchange.com/questions/5694/dimensionality-and-manifold
* Play with Generative Adverserial Networks: https://poloclub.github.io/ganlab/

### CNN and Image Processing:

* Why do we need to normalize the images before we put them into CNN? : https://stats.stackexchange.com/questions/185853/why-do-we-need-to-normalize-the-images-before-we-put-them-into-cnn
* Neural Network data type conversion - float from int? : https://datascience.stackexchange.com/questions/13636/neural-network-data-type-conversion-float-from-int
* Image Pre-processing (Keras): https://keras.io/preprocessing/image/
* Trick to prevent Overfitting: https://hackernoon.com/memorizing-is-not-learning-6-tricks-to-prevent-overfitting-in-machine-learning-820b091dc42
* keras callbacks: https://keras.io/callbacks/
* How to Check-Point Deep Learning Models in Keras: https://machinelearningmastery.com/check-point-deep-learning-models-keras/
* In Depth understanding of Convolutions: http://timdettmers.com/2015/03/26/convolution-deep-learning/
* friendly introduction to Cross Entropy: https://rdipietro.github.io/friendly-intro-to-cross-entropy-loss/
* Understanding Cross Entropy Loss - Visual Information Theory: http://timdettmers.com/2015/03/26/convolution-deep-learning/
* Papers on imp CNN architectures: https://adeshpande3.github.io/adeshpande3.github.io/The-9-Deep-Learning-Papers-You-Need-To-Know-About.html
* CNN using numpy: https://becominghuman.ai/only-numpy-implementing-convolutional-neural-network-using-numpy-deriving-forward-feed-and-back-458a5250d6e4


## References (technical):

* plotting boxplots in plotly in python: https://plot.ly/python/box-plots/
* extract high correlation values: https://stackoverflow.com/questions/17778394/list-highest-correlation-pairs-from-a-large-correlation-matrix-in-pandas
* converting group by object to data frame (also how to avoid converting columns to indices when doing group by):https://stackoverflow.com/questions/10373660/converting-a-pandas-groupby-object-to-dataframe
* **matplotlib** basic tutorial: https://www.datacamp.com/community/tutorials/matplotlib-tutorial-python
* parametric and non-parametric ml methods: https://machinelearningmastery.com/parametric-and-nonparametric-machine-learning-algorithms/
* Stability Selection vs RFE (Recursive Feature Elimination): http://blog.datadive.net/selecting-good-features-part-iv-stability-selection-rfe-and-everything-side-by-side/

* **Scikit learn**: http://scikit-learn.org/stable/index.html

## feature scaling
* Standardisation vs Normalization:  https://stackoverflow.com/questions/32108179/linear-regression-normalization-vs-standardization
* Importance of Feature Scaling: http://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html
* feature Scaling with scikit-learn (good): http://benalexkeen.com/feature-scaling-with-scikit-learn/
* about feature scaling (bit mathematical): http://sebastianraschka.com/Articles/2014_about_feature_scaling.html


* How is Bayesian classifer different from MLE classifier?: https://stats.stackexchange.com/questions/74082/what-is-the-difference-in-bayesian-estimate-and-maximum-likelihood-estimate
* ROC : https://stats.stackexchange.com/questions/105501/understanding-roc-curve
* ROC detailed analysis: http://mlwiki.org/index.php/ROC_Analysis
* Cross Validation - need for test set: https://stats.stackexchange.com/questions/223408/how-does-k-fold-cross-validation-fit-in-the-context-of-training-validation-testi AND
https://stackoverflow.com/questions/43663365/cross-validation-use-testing-set-or-validation-set-to-predict
* K Modes Clustering: https://shapeofdata.wordpress.com/2014/03/04/k-modes/
* Hirarchial Clustering: http://www.saedsayad.com/clustering_hierarchical.htm
* Linkage methods of hierarchical agglomerative cluster analysis (HAC): https://stats.stackexchange.com/questions/195446/choosing-the-right-linkage-method-for-hierarchical-clustering
* why LASSO shrinkag works: https://stats.stackexchange.com/questions/179864/why-does-shrinkage-work
* p value: https://www.statsdirect.com/help/basics/p_values.htm
* multicollinearity in regression analysis: http://statisticsbyjim.com/regression/multicollinearity-in-regression-analysis/
* Effect of multicollinearity on Ordinary Least Squares solution for regression: https://en.wikipedia.org/wiki/Multicollinearity
* Why is gradient descent or optimization methods required at all if cost function minima can be found directly say by using linear algebra or differentiation ? : https://stats.stackexchange.com/questions/212619/why-is-gradient-descent-required
https://stats.stackexchange.com/questions/278755/why-use-gradient-descent-for-linear-regression-when-a-closed-form-math-solution
* normality tests in python: https://machinelearningmastery.com/a-gentle-introduction-to-normality-tests-in-python/
* parametric significance tests in python: https://machinelearningmastery.com/parametric-statistical-significance-tests-in-python/
* non-parametric significance tests in python: https://machinelearningmastery.com/nonparametric-statistical-significance-tests-in-python/
* Introduction to Matrix Decomposition: https://machinelearningmastery.com/introduction-to-matrix-decompositions-for-machine-learning/
* How to Compare ML models: https://machinelearningmastery.com/compare-machine-learning-algorithms-python-scikit-learn/
* Beginners guide to Jupyter Notebooks: https://www.analyticsvidhya.com/blog/2018/05/starters-guide-jupyter-notebook/?utm_source=feedburner&utm_medium=email&utm_campaign=Feed%3A+AnalyticsVidhya+%28Analytics+Vidhya%29
* matplotlib plotting in 2D and 3D: http://nbviewer.jupyter.org/github/jrjohansson/scientific-python-lectures/blob/master/Lecture-4-Matplotlib.ipynb
* Computational Quantum Mechanics with Python: http://jrjohansson.github.io/

## Boosting:
* A gentle introduction to boosting algos: https://machinelearningmastery.com/gentle-introduction-gradient-boosting-algorithm-machine-learning/
* CatBoost Algorithm resources: https://tech.yandex.com/catboost/
* Light GBM: http://lightgbm.readthedocs.io/en/latest/index.html
* Light GBM github: https://github.com/Microsoft/LightGBM
* XGBoost Conceptual Understanding of Algo: http://xgboost.readthedocs.io/en/latest/model.html
* XGBoost Site: http://xgboost.readthedocs.io/en/latest/


* Difference b/w size and count with groupby in pandas: https://stackoverflow.com/questions/33346591/what-is-the-difference-between-size-and-count-in-pandas
* ML crash course by google: https://developers.google.com/machine-learning/crash-course/prereqs-and-prework
* pandas regex to create columns: https://chrisalbon.com/python/data_wrangling/pandas_regex_to_create_columns/
* regex in python and pandas: https://www.dataquest.io/blog/regular-expressions-data-scientists/

* Book on Feature Engineering (Max Kuhn): http://www.feat.engineering/
* Understanding Cost Functions (video series): https://www.youtube.com/watch?v=euhATa4wgzo&index=1&list=PLNlkREaquqc6WUPMRicPbEvLyZe-7b-GT
* Build better predictive models using segmentation: https://www.analyticsvidhya.com/blog/2016/02/guide-build-predictive-models-segmentation/
* metrics for model evaluation: http://scikit-learn.org/stable/modules/model_evaluation.html

* using AWS for Deep Learning: https://machinelearningmastery.com/develop-evaluate-large-deep-learning-models-keras-amazon-web-services/

**t-SNE**
* Laurens van der Maaten's (creator of t-SNE) website: https://lvdmaaten.github.io/tsne/
* Visualising data using t-SNE: Journal of Machine Learning Research: http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf
* How to use t-SNE effectively: https://distill.pub/2016/misread-tsne/

**ICA**
* Stanford notes on ICA: http://cs229.stanford.edu/notes/cs229-notes11.pdf

## Docker
* https://www.analyticsvidhya.com/blog/2017/11/reproducible-data-science-docker-for-data-science/
* Docker for ML: https://pratos.github.io/2017-04-24/docker-for-data-science-part-1/
* conceptual - introduction to VM's and Docker: https://medium.freecodecamp.org/a-beginner-friendly-introduction-to-containers-vms-and-docker-79a9e3e119b

#### Handling imbalanced data set:
* how to handle imbalanced data with code: https://elitedatascience.com/imbalanced-classes
* good read: https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/
* concept read: https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/
* imbalanced-learn library: https://github.com/scikit-learn-contrib/imbalanced-learn
* anomaly detection in python: https://www.datascience.com/blog/python-anomaly-detection
* scikit learn novelty and outlier detection: https://www.datascience.com/blog/python-anomaly-detection
* Imbalanced data handling tutorial in Python: https://blog.dominodatalab.com/imbalanced-datasets/

## NLP:
* NLTK Book: http://www.nltk.org/book/ 
* SpaCy: Industrial grad NLP: https://spacy.io/
* Genism: https://radimrehurek.com/gensim/index.html
* NLTK tutorial: https://pythonprogramming.net/tokenizing-words-sentences-nltk-tutorial/
* Lyric Analysis with NLP and ML in R part 1: https://www.datacamp.com/community/tutorials/R-nlp-machine-learning
* Lyric Analysis with NLP and ML in R part 2A:https://www.datacamp.com/community/tutorials/R-nlp-machine-learning
* Lyric Analysis with NLP and ML in R part 2B:https://www.datacamp.com/community/tutorials/sentiment-analysis-R
* Text Encoding Unicode: https://docs.python.org/3/howto/unicode.html

* Generate text using word level neural language model: https://machinelearningmastery.com/how-to-develop-a-word-level-neural-language-model-in-keras/
* Generate text using LSTM: https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/

### XGBoost Installation:

* check you python version - by opening CMD and typing python -> ENTER
* Go to this link and search on XGBoost: https://www.lfd.uci.edu/~gohlke/pythonlibs/
* download the installable based on python version + Windows 32 or 64 bit, for example download xgboost-0.71-cp36-cp36m-win_amd64.whl for python version 3.6 and 64 bit machine.
* open cmd in downloaded location and run the following command: pip install xgboost-0.71-cp36-cp36m-win_amd64.whl

### Python
* Python OOP tutorial: https://www.youtube.com/watch?v=ZDa-Z5JzLYM

* Use YouTube as a Free Screencast Recorder: https://www.youtube.com/watch?v=0i9C8GpRedc

## References (business):
* What is an ad impression: https://www.mediapost.com/publications/article/219695/the-definition-of-an-ad-impression.html
* ML in fraud detection: https://www.marutitech.com/machine-learning-fraud-detection/
* Customer Segmentation: http://analyticstraining.com/2011/cluster-analysis-for-business/
* Telecom churn customer model: https://parcusgroup.com/Telecom-Customer-Churn-Prediction-Models
* customer churn in mobile markets: https://arxiv.org/ftp/arxiv/papers/1607/1607.07792.pdf
